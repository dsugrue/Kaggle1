{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Data Cleaning (Houses in Iowa Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data Science Workflow\n",
    "\n",
    "In general, there are a few key steps to begin working with a dataset.\n",
    "\n",
    "First, we need to understand what the dataset actually is about, and what we are trying to \n",
    "do with it. Key to this stage is understanding what each row of the dataset represents, as \n",
    "well as what each column indicates. You can read more about this dataset by looking at the \n",
    "dataset itself (https://www.kaggle.com/c/house-prices-advanced-regression-techniques/), or \n",
    "reading the data dictionary in crash-course/Kaggle/DATA/house-prices/data_description.txt.\n",
    "\n",
    "Second, before we can even do exploratory data analysis, we need to __clean our dataset__. \n",
    "It is very helpful to identify the size of the dataset, so we know how many samples we \n",
    "have. We need to determine a consistent method of dealing with missing values, such as \n",
    "setting them to a value, removing the feature entirely, interpolating values, etc. Other \n",
    "crucial steps are separating into training and validation, as well as creating elementary \n",
    "data plots.\n",
    "\n",
    "Third, we have exploratory data analysis (EDA). The point of this phase is to inspect & \n",
    "visualize key relationships, trends, outliers, and issues with our data. By conducting \n",
    "EDA, we get a better sense of the underlying structure of our data, and which features are \n",
    "most important. Especially since we have 81 features, we would like to select the features \n",
    "that are most important to our analysis before we begin modeling SalePrice. Once we have \n",
    "an idea about which features to use and how they relate to one another, our modeling stage \n",
    "will be more informed and robust.\n",
    "\n",
    "Fourth, we have the modeling phase, consisting of model selection and model training. \n",
    "Here, we select a predictive model to train on our features, and then actually train the \n",
    "model! In this first week, we will be using linear regression as a first-pass. In later \n",
    "weeks of the SUSA CX Kaggle Capstone project, we will be using more advanced models like \n",
    "random forest and neural networks. Depending on the model we are using, it is important to \n",
    "verify the model's assumptions before fully pledging to that model. Additionally, we may \n",
    "use validation in this stage to select certain hyperparameters for our model selection.\n",
    "\n",
    "Finally, we have the model evaluation phase. Here, we compute a metric for our model's \n",
    "performance, usually by summing the squared errors of the model's predictions on the test \n",
    "set. This stage allows us to effectively compare various data cleaning and modeling \n",
    "selection decisions, by giving us a single comparable value for performance across our \n",
    "potential models.\n",
    "I. Understanding our Dataset\n",
    "\n",
    "Our dataset is about houses in Iowa! According to the Kaggle webpage, the competition is \n",
    "as follows:\n",
    "\n",
    "Ask a home buyer to describe their dream house, and they probably won’t begin with the \n",
    "height of the basement ceiling or the proximity to an east-west railroad. But this \n",
    "playground competition’s dataset proves that much more influences price negotiations than \n",
    "the number of bedrooms or a white-picket fence. With 79 explanatory variables describing \n",
    "(almost) every aspect of residential homes in Ames, Iowa, this competition challenges you \n",
    "to predict the final price of each home.\n",
    "\n",
    "More explicitly, our dataset has 81 columns, or features:\n",
    "\n",
    "SalePrice, our response variable $Y$ that we are trying to predict accurately and \n",
    "precisely\n",
    "Id, a simple identification variable\n",
    "79 explanatory variables $X_k$ that we can use to predict SalePrice. Some of the variables \n",
    "are categorical, and others are continuous quantitative.\n",
    "The goal of the next four weeks to to create a model that trains on (some of) the 79 \n",
    "explanators from the training set to predict SalePrice well in the test set.\n",
    "\n",
    "How will we know which explanators to use? We can start with some intuition and research \n",
    "into what each column represents by reading the data dictionary in crash-\n",
    "course/Kaggle/DATA/house-prices/data_description.txt.\n",
    "\n",
    "Please take a moment to read over this dictionary, as you will need to have a keen sense \n",
    "of these features for the weeks ahead. Can you come up with five features you suspect will \n",
    "be important in determining the SalePrice?\n",
    "\n",
    "Now that we've talked a bit about this dataset, let's actually take a look at it. The \n",
    "first step is to load in the data! We will store this in a  pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
